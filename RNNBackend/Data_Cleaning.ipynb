{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Data\n",
    "data = pd.read_csv(\"Donald-Tweets!.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning\n",
    "data = data[pd.isnull(data['Hashtags'])]\n",
    "data = data[pd.isnull(data['Media_Type'])]\n",
    "data = data[data.Type == \"text\"]\n",
    "df = data[[\"Tweet_Text\"]]\n",
    "df = df[~df.Tweet_Text.str.contains(\"RT @\")]\n",
    "df = df[~df.Tweet_Text.str.contains(\"http\")]\n",
    "df = df[~df.Tweet_Text.str.contains('\"')]\n",
    "df = df.replace({'&amp;': '&'}, regex=True)\n",
    "df.to_csv('Donald-Tweets-Cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some More Data Cleaning and Converting Dataframe to Text File\n",
    "file = open(\"donald-tweets-clean.txt\", \"w\")\n",
    "file.truncate(0)\n",
    "for i in df:\n",
    "    i = i.replace(\"&amp;\", \"&\")\n",
    "    file.write(i + \"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-66a10da649f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Donald-Tweets-Cleaned.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"Donald-Tweets-Cleaned.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 8)\n",
      "(142, 8)\n",
      "(774, 8)\n",
      "(3531, 8)\n",
      "(8144, 8)\n",
      "(5784, 8)\n",
      "(7536, 8)\n",
      "(4225, 8)\n",
      "(2605, 8)\n",
      "(3510, 8)\n",
      "(36307, 8)\n"
     ]
    }
   ],
   "source": [
    "data1 = pd.read_json(\"trump_tweet_data_archive/condensed_2009.json\")\n",
    "print(data1.shape)\n",
    "data2 = pd.read_json(\"trump_tweet_data_archive/condensed_2010.json\")\n",
    "print(data2.shape)\n",
    "data3 = pd.read_json(\"trump_tweet_data_archive/condensed_2011.json\")\n",
    "print(data3.shape)\n",
    "data4 = pd.read_json(\"trump_tweet_data_archive/condensed_2012.json\")\n",
    "print(data4.shape)\n",
    "data5 = pd.read_json(\"trump_tweet_data_archive/condensed_2013.json\")\n",
    "print(data5.shape)\n",
    "data6 = pd.read_json(\"trump_tweet_data_archive/condensed_2014.json\")\n",
    "print(data6.shape)\n",
    "data7 = pd.read_json(\"trump_tweet_data_archive/condensed_2015.json\")\n",
    "print(data7.shape)\n",
    "data8 = pd.read_json(\"trump_tweet_data_archive/condensed_2016.json\")\n",
    "print(data8.shape)\n",
    "data9 = pd.read_json(\"trump_tweet_data_archive/condensed_2017.json\")\n",
    "print(data9.shape)\n",
    "data10 = pd.read_json(\"trump_tweet_data_archive/condensed_2018.json\")\n",
    "print(data10.shape)\n",
    "data_comb = pd.concat([data1, data2, data3, data4, data5, data6, data7, data8, data9, data10], axis=0)\n",
    "print(data_comb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35345, 1)\n"
     ]
    }
   ],
   "source": [
    "data_comb = data_comb[data_comb[\"is_retweet\"]==False]\n",
    "data_comb = data_comb.drop(columns=['created_at', 'favorite_count', 'id_str', 'in_reply_to_user_id_str', 'is_retweet', 'retweet_count', 'source'])\n",
    "data_comb.head()\n",
    "print(data_comb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_comb.reset_index(drop=True, inplace=True)\n",
    "data_comb.to_json('Donald-Tweets-New-Cleaned.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9733, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"Donald-Tweets-New-Cleaned.json\")\n",
    "df = df[~df.text.str.contains(\"@\")]\n",
    "df = df[~df.text.str.contains(\"http\")]\n",
    "df = df[~df.text.str.contains('\"')]\n",
    "df.to_json('Donald-Tweets-New-Cleaned.json')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"donald-tweets-new-clean.txt\", \"w\")\n",
    "file.truncate(0)\n",
    "for i in df[\"text\"]:\n",
    "    i = i.replace(\"&amp;\", \"&\")\n",
    "    file.write(i + \"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame([], columns=['text'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From Donald Trump: Wishing everyone a wonderfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spent a beautiful weekend golfing at Trump Nat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yea, NBC has increased all remaining Celebrity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It’s Tuesday, how much has China stolen from u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Don't negate your own power. Whatever you've b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  From Donald Trump: Wishing everyone a wonderfu...\n",
       "1  Spent a beautiful weekend golfing at Trump Nat...\n",
       "2  Yea, NBC has increased all remaining Celebrity...\n",
       "3  It’s Tuesday, how much has China stolen from u...\n",
       "4  Don't negate your own power. Whatever you've b..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in df[\"text\"]:\n",
    "    data = data.append({'text': i}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       From Donald Trump: Wishing everyone a wonderfu...\n",
       "1       Spent a beautiful weekend golfing at Trump Nat...\n",
       "2       Yea, NBC has increased all remaining Celebrity...\n",
       "3       It’s Tuesday, how much has China stolen from u...\n",
       "4       Don't negate your own power. Whatever you've b...\n",
       "5       Think positively. There are always opportuniti...\n",
       "6       The new reality. ‘China Daily’ is sold in stre...\n",
       "7       Margaret Thatcher was the Iron Lady of the Wes...\n",
       "8              What do you think so far? #CelebApprentice\n",
       "9       “To be successful, you must become very good a...\n",
       "10      Dennis Rodman is a project manager tonight on ...\n",
       "11      Republicans remember—debt ceiling, debt ceilin...\n",
       "12      Starting next week, and by popular demand (plu...\n",
       "13      My induction last night at Madison Square Gard...\n",
       "14      It’s Thursday.  How much time did Washington w...\n",
       "15      True, America is rapidly losing it's SPIRIT, a...\n",
       "16                          China is pushing North Korea!\n",
       "17      When is South Korea going to start paying us f...\n",
       "18      Our President must be very careful with the 28...\n",
       "19      I'm getting ready to be inducted tonight into ...\n",
       "20      I am doing On the Record With Greta Van Suster...\n",
       "21      I told the Republicans the debt ceiling talks ...\n",
       "22      “The great question is not whether you have fa...\n",
       "23      Only 88,000 jobs were added this past March. P...\n",
       "24      ...Who says the death penalty is not a deterrent?\n",
       "25      James Holmes, the Aurora, Colorado guy who kil...\n",
       "26      Jobs report is really bad - beyond the worst p...\n",
       "27      Word is spreading that I got a tattoo - no way...\n",
       "28      North Korea can't survive, or even eat, withou...\n",
       "29      The Miss Universe Pageant raked in some great ...\n",
       "                              ...                        \n",
       "9703    South Korea must in some form pay for our help...\n",
       "9704    The Republicans once again hold all the cards ...\n",
       "9705    China will extract much from Secretary Kerry a...\n",
       "9706    Did A Rod really try to buy the papers that wo...\n",
       "9707    Remember, NBC increased Celebrity Apprentice t...\n",
       "9708    What a shame that Kobe Bryant was so badly inj...\n",
       "9709    Ridiculous that they gave the 14 year old golf...\n",
       "9710                     I am on David Letterman tonight.\n",
       "9711    Our country should be worried about nuclear co...\n",
       "9712    Remember to take time this weekend to relax an...\n",
       "9713    Always remember that as your success grows, yo...\n",
       "9714    “Be up front and direct with people, and they ...\n",
       "9715    Where is the President?  It is time for him to...\n",
       "9716    The only American who has met with the North K...\n",
       "9717    China controls North Korea. So now besides cyb...\n",
       "9718    Went to the Yankees game last night with Bill ...\n",
       "9719    Don't talk to me about Bush, I was never a def...\n",
       "9720    I can't believe we are not asking South Korea ...\n",
       "9721    Sorry to hear of yesterday’s passing of Genera...\n",
       "9722    “Interested is interesting. If you remember th...\n",
       "9723    Mr. President, it is time to lead on the Korea...\n",
       "9724    Opportunities only present themselves if you a...\n",
       "9725    “Go for the jugular so that people watching wi...\n",
       "9726    I feel so badly for Mark Cuban-the Dallas Mave...\n",
       "9727    “You cannot push anyone up the ladder unless h...\n",
       "9728    Sexual pervert Anthony Weiner has zero busines...\n",
       "9729    “Success breeds success. The best way to impre...\n",
       "9730    I hope everyone (especially the haters and los...\n",
       "9731    Sorry losers and haters, but I LOVED the great...\n",
       "9732    Why did Vince and the WWE give my speech and s...\n",
       "Name: text, Length: 9733, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Donald-Tweets-New-Cleaned.csv\")\n",
    "data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
